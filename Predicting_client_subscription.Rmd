---
title: "Predicting_client_subscription"
author: "Felix Seo"
date: '2022-07-04'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
library(caret)
library(mlbench)
library(tidyverse)
library(corrplot)
library(rcompanion)
library(glmnet)
library(gglasso)
library(rpart)
library(rpart.plot)
library(plotROC)
library(latex2exp)
```

```{r}
bank_data <- read_delim("Data/bank_additional_full.csv", delim = ";")
```


```{r}
# data preparation 
bank_data_mod <- bank_data %>% 
  dplyr::select(-duration, -default) %>% 
  mutate(
    temp1 = 1, 
    temp2 = 1,
    temp3 = 1, 
    temp4 = 1,
    temp5 = 1,
    id_col = seq(1, length(bank_data$job), 1)
  ) %>% #id_col because pivot easy to work with then, removed later
  filter(if_all(job:loan, ~ . != "unknown")) %>% 
  pivot_wider(names_from = job, values_from = temp1, values_fill = 0) %>% 
  pivot_wider(names_from = marital, values_from = temp2, values_fill = 0) %>% 
  pivot_wider(names_from = month, values_from = temp3, values_fill = 0) %>%
  pivot_wider(names_from = day_of_week, values_from = temp4, values_fill = 0) %>% 
  pivot_wider(names_from = poutcome, values_from = temp5, values_fill = 0) %>% 
  mutate(
    education = str_replace(education, "illiterate", "0"),
    education = str_replace(education, "basic.4y", "1"),
    education = str_replace(education, "basic.6y", "2"),
    education = str_replace(education, "basic.9y", "3"),
    education = str_replace(education, "high.school", "4"),
    education = str_replace(education, "professional.course", "5"),
    education = str_replace(education, "university.degree", "6"),
    education = as.numeric(education)
  ) %>%
  mutate(
    housing = if_else(housing == "yes", 1, 0),
    loan = if_else(loan == "yes", 1, 0),
    contact = if_else(contact == "cellular", 1, 0), #0 means telephone, 1 cellular.
    y = if_else(y == "yes", 1, 0)
  ) %>% 
  rename(
    "blue.collar" = "blue-collar",  #donÂ´t like variables with -. 
    "self.employed" = "self-employed"
  ) %>% 
  select(-id_col) 

bank_data_mod
```

```{r}
#The gglasso package. group lasso method. I try under-sampling the data
set.seed(990108)

success_y <- bank_data_mod %>% 
  filter(y == 1)

data_under_samp <- bank_data_mod %>% 
  filter(y == 0) %>% 
  slice_sample(n = length(success_y$y)) %>% 
  add_row(success_y) %>% 
  slice_sample(prop = 1) #randomize the rows, before they where ordered
  
groups = c(seq(1, 13), rep(14, 10), rep(15, 2), rep(16, 9), rep(17, 4), rep(18, 2))

train_under_samp <- data_under_samp %>% 
  slice_head(prop = 0.8) #rows already randomized 
  
test_under_samp <- data_under_samp %>% 
  slice_tail(prop = 0.2)

bank_data_glasso <- data_under_samp %>% 
  select(-y, -student, -divorced, -dec, -fri, -nonexistent) %>% # k classes to k-1 dummy 
  scale() %>% #standardized data for lasso.
  as.data.frame() %>% 
  add_column(y = data_under_samp$y)

train_glasso_pred <- bank_data_glasso %>% 
  select(-y) %>% 
  slice_head(prop = 0.8) %>%  # data already randomized
  as.matrix()

train_glasso_y <- bank_data_glasso %>% 
  select(y) %>%
  slice_head(prop = 0.8) %>% 
  mutate(y = if_else(y == 0, -1, y)) %>% #gglasso wants -1/1 responses only
  as.matrix()
    
test_glasso_pred <- bank_data_glasso %>% 
  select(-y) %>% 
  slice_tail(prop = 0.2)

test_glasso_y <- bank_data_glasso %>% 
  select(y) %>%
  slice_tail(prop = 0.2) %>% 
  mutate(y = if_else(y == 0, -1, y)) %>% #gglasso wants -1/1 responses only
  as.matrix()

cv_glasso_default <- cv.gglasso(  # defaults parameter for pf = sqrt(bs).
  train_glasso_pred,
  train_glasso_y,
  group = groups,
  loss = "logit",
  lambda.factor = 0.0001,
  pred.loss = "loss",
  nfolds = 10
)

model_glasso_default <- gglasso(
  train_glasso_pred, #only predictors chosen
  train_glasso_y,
  group = groups,
  loss = "logit",
  lambda.factor = 0.0001
)

model_glasso_1se <- gglasso(
  train_glasso_pred, #only predictors chosen
  train_glasso_y,
  group = groups,
  loss = "logit",
  lambda = cv_glasso_default$lambda.1se
)
```

```{r}

png(file = "cv_glasso_default.png")
plot(cv_glasso_default, xlab = TeX(r'($\log{(\lambda)}$)'))
dev.off()

png(file = "glasso_coefpath_default.png")
plot(model_glasso_default, xlab = TeX(r'($\log{(\lambda)}$)'))
abline(v = log(cv_glasso_default$lambda.min), lty = 3)
abline(v = log(cv_glasso_default$lambda.1se), lty = 3)
dev.off()
```

```{r}
model_glasso_default <- gglasso(
  train_glasso_pred, #only predictors chosen
  train_glasso_y,
  group = groups,
  loss = "logit",
  lambda = cv_glasso_default$lambda.min
)

default_pred <- predict(model_glasso_default, newx = train_glasso_pred, type = "link") %>% 
  as.data.frame() %>% 
  rename("glasso_def" = "s0") %>% 
  mutate(y = train_under_samp$y,  glass_def = 1 / (1 + 2.718^-glasso_def))

glasso_1se_pred <- predict(model_glasso_1se, newx = train_glasso_pred, type = "link") %>% 
  as.data.frame() %>% 
  rename("glasso_1se" = "s0") %>% 
  mutate(glasso_1se = 1 / (1 + 2.718^-glasso_1se))

roc_curve_def_1se <- default_pred %>% 
  add_column("glasso_1se" = glasso_1se_pred$glasso_1se) %>%
  rename("Model 1" = "glasso_def", "Model 2" = "glasso_1se") %>%  
  melt_roc(d = "y", m = c("Model 1", "Model 2")) %>% 
  ggplot(aes(d = D, m = M, color = name)) + 
  geom_roc(labelround = 1, labelsize = 2.5, cutoffs.at = 0.5) +
  geom_abline(slope = 1, intercept = 0) +
  labs(x = "1 - Specificity", y = "Sensitivity") 

ggsave("roc_curve_def_1se.png")

########### probably not use the below, remove when finished with report
simplest_pred <- predict(model_glasso_simplest, newx = train_glasso_pred, type = "link") %>% 
  as.data.frame() %>% 
  rename("glasso_simple" = "s0") %>% 
  mutate(y = train_under_samp$y, glasso_simple = 1 / (1 + 2.718^-glasso_simple))

roc_curve_1se_simplest <- simplest_pred %>% 
  add_column("glasso_1se" = glasso_1se_pred$glasso_1se) %>% 
  melt_roc(d = "y", m = c("glasso_1se", "glasso_simple")) %>% 
  ggplot(aes(d = D, m = M, color = name)) + 
  geom_roc(labelround = 2, labelsize = 2.5) +
  geom_abline(slope = 1, intercept = 0) +
  labs(x = "1 - Specificity", y = "Sensitivity")

ggsave("roc_curve_simple_1se.png")
###########
```

```{r}
set.seed(990108)
# classification trees 

# Fixing the nominal data to be ordered proportions in accordance with ESL
# (Elements of statistical learning)
bank_data_tree <- bank_data %>% 
  select(-duration, -default)  %>% 
  filter(if_all(job:y, ~ . != "unknown")) %>% 
  mutate(
    education = str_replace(education, "illiterate", "0"),
    education = str_replace(education, "basic.4y", "1"),
    education = str_replace(education, "basic.6y", "2"),
    education = str_replace(education, "basic.9y", "3"),
    education = str_replace(education, "high.school", "4"),
    education = str_replace(education, "professional.course", "5"),
    education = str_replace(education, "university.degree", "6"),
    education = as.numeric(education)
  ) %>%
  mutate(
    housing = if_else(housing == "yes", 1, 0),
    loan = if_else(loan == "yes", 1, 0),
    contact = if_else(contact == "cellular", 1, 0),
    y = if_else(y == "yes", 1, 0),
    poutcome = if_else(poutcome == "success", 1, 0)
  ) 

data_tree_success <- bank_data_tree %>% 
  filter(y == 1)
  
data_tree_balanced <- bank_data_tree %>% 
  filter(y == 0) %>% 
  slice_sample(n = length(data_tree_success$y)) %>% 
  add_row(data_tree_success) %>% 
  group_by(job) %>% 
  mutate(job = sum(y) / length(data_tree_success$y)) %>% # the prop of successes in each job, mean works since 1/0 outcome
  ungroup() %>%
  group_by(marital) %>% 
  mutate(marital = sum(y) / length(data_tree_success$y)) %>% # the prop of successes in each marital, mean works since 1/0 outcome
  ungroup() %>%
  group_by(month) %>% 
  mutate(month = sum(y) / length(data_tree_success$y)) %>% # ----||----
  ungroup() %>%
  group_by(day_of_week) %>% 
  mutate(day_of_week = sum(y) / length(data_tree_success$y)) %>% # ----||----
  ungroup() %>%  
  slice_sample(prop = 1) %>% # randomize, same as for glasso since set.seed is same.
  mutate(across(c(job, marital, month, day_of_week), ~ round(.x, digits = 3))) %>% 
  mutate(across(c(housing:contact, poutcome), ~ as.factor(.x))) %>% 
  mutate(across(c(job, marital, education, month, day_of_week), ~ as.ordered(.x))) %>% 
  mutate(y = as.factor(y))


train_tree <- data_tree_balanced %>% slice_head(n = 0.8*length(data_tree_balanced$y))
test_tree <- data_tree_balanced %>% slice_tail(n = 0.2*length(data_tree_balanced$y))

# build large tree to later prune.
tree_parameters <- rpart.control(minsplit = 30, maxcompete = 5, maxdepth = 30, cp =  0.000001)
tree_model <- rpart(y ~ ., data = train_tree, method = "class", control = tree_parameters)

min_err <- tree_model$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"]

pruned_tree_opt <- prune(tree_model, cp = min_err)
pruned_tree_1se <- prune(tree_model, cp = 3.247712e-03)

png(filename = "pruned_tree_opt.png", res = 150)
rpart.plot(pruned_tree_opt, extra = 106, tweak = 1.2)
dev.off()

png(filename = "pruned_tree_1se.png", res = 150)
rpart.plot(pruned_tree_1se, extra = 106, tweak = 1)
dev.off()

png(filename = "cp_plot_tree.png")
plotcp(tree_model) 
dev.off()

# info on the splits, variable importance etc. 
summary(pruned_tree_1se)

```

```{r}
############ roc for test data, remove later if it is not used, high probability
roc_curve <- test2 %>%
  as.data.frame() %>% 
  rename("pred_tree" = "1", "remove" = "0") %>% 
  select(-remove) %>% 
  add_column("pred_glasso" = test$pred) %>% 
  mutate(y = test_tree$y, y = as.numeric(y), y = if_else(y == 2, 1, 0)) %>% 
  melt_roc(d = "y", m = c("pred_tree", "pred_glasso")) %>% 
  ggplot(aes(d = D, m = M, color = name)) +
  geom_roc(labelround = 2) +
  geom_abline(slope = 1, intercept = 0) 

ggsave("roc_curve.png")
###################
```

```{r}
# roc for train data
pred_tree_1se <- predict(pruned_tree_1se, newdata = train_tree, type = "prob")
rownames(pred_tree_1se) <- NULL

pred_glasso_1se <- predict(model_glasso_1se, newx = train_glasso_pred, type = "link") %>% 
  as.data.frame() %>% 
  rename("glasso" = "s0") %>% 
  mutate(y = train_under_samp$y, glasso = 1 / (1 + 2.718^-glasso))

roc_curve_tree_glasso <- pred_tree_1se %>% 
  as.data.frame() %>% 
  select(-"0") %>% 
  rename("Classification tree" = "1") %>% 
  mutate("Group-lasso" = pred_glasso_1se$glasso, y = train_tree$y) %>%
  mutate(y = as.numeric(y), y = if_else(y == 2, 1, 0)) %>% 
  melt_roc(d = "y", m = c("Group-lasso", "Classification tree")) %>% 
  ggplot(aes(d = D, m = M, color = name)) +
  geom_roc(labelround = 2, labelsize = 2.5, cutoffs.at = c(0.5, 0.36)) + 
  geom_abline(slope = 1, intercept = 0) +
  labs(x = "1 - Specificity", y = "Sensitivity")

roc_curve_tree_glasso

ggsave("roc_curve_tree_glasso.png", width = 7, height = 7)

model_glasso_1se$beta  # coefficients for 1-se group lasso.
model_glasso_1se$b0    # The intercept term  
```

```{r}
# confusion matrices for the tree and lasso, change x in pred >= x, to get 
# different threshold values to test on.
test_pred_tree <- predict(pruned_tree_1se, newdata = test_tree[, -19], type = "prob")  
rownames(test_pred_tree) <- NULL  
test_pred_tree %>% 
  as.data.frame() %>% 
  select(- "0") %>%
  rename("pred" = "1") %>% 
  mutate(pred = if_else(pred >= 0.33, 1, 0), pred = as.factor(pred), ref = test_tree$y) %>% 
  {confusionMatrix(.$pred, .$ref, positive = "1")}

test_glasso_pred %>%  
  {predict(model_glasso_1se, newx = ., type = "link")} %>% 
  as.data.frame() %>% 
  rename("pred" = "s0") %>% 
  mutate(
    ref = as.data.frame(test_glasso_y)$y, 
    pred = 1 / (1 + 2.718^-pred),
    pred = if_else(pred >= 0.33, 1, -1),
    pred = as.factor(pred),
    ref = as.factor(ref)
  ) %>% 
  {confusionMatrix(.$pred, .$ref, positive = "1")} 
```











